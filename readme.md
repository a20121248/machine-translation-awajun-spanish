cd /home/jmonzon/machine-translation-awajun-spanish_backup/
source /home/jmonzon/envs/nllb-2/bin/activate


# üöÄ Comandos para Experimentos NLLB

## üìÅ Estructura de directorios requerida
```
proyecto/
‚îú‚îÄ‚îÄ config.yaml
‚îú‚îÄ‚îÄ train.py
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py
‚îÇ   ‚îú‚îÄ‚îÄ model.py
‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py
‚îÇ   ‚îú‚îÄ‚îÄ training.py
‚îÇ   ‚îî‚îÄ‚îÄ utils.py
‚îî‚îÄ‚îÄ data/
    ‚îú‚îÄ‚îÄ awajun-spanish-v1/     # Dataset normal
    ‚îÇ   ‚îú‚îÄ‚îÄ train.agr
    ‚îÇ   ‚îú‚îÄ‚îÄ train.es
    ‚îÇ   ‚îú‚îÄ‚îÄ train.source
    ‚îÇ   ‚îú‚îÄ‚îÄ dev.agr
    ‚îÇ   ‚îú‚îÄ‚îÄ dev.es
    ‚îÇ   ‚îî‚îÄ‚îÄ dev.source
    ‚îî‚îÄ‚îÄ awajun-spanish-v2/     # Dataset extendido
        ‚îú‚îÄ‚îÄ train.agr
        ‚îú‚îÄ‚îÄ train.es
        ‚îú‚îÄ‚îÄ train.source
        ‚îú‚îÄ‚îÄ dev.agr
        ‚îú‚îÄ‚îÄ dev.es
        ‚îî‚îÄ‚îÄ dev.source
```

## üß™ Comandos de Prueba R√°pida (1-2 minutos)

### Verificar que todo funciona
```bash
# Prueba b√°sica es2agr
python train.py --direction es2agr --dataset_version v1 --test_mode

# Prueba b√°sica agr2es  
python train.py --direction agr2es --dataset_version v1 --test_mode

# Prueba con dataset extendido
python train.py --direction es2agr --dataset_version v2 --test_mode
```

## üî¨ Experimentos Reales

### Configuraci√≥n Base (recomendada)
```bash
# Espa√±ol ‚Üí Awaj√∫n (dataset normal)
python train.py --direction es2agr --dataset_version v1 --epochs 12 --batch_size 16 --learning_rate 3e-5 --patience 3

# Awaj√∫n ‚Üí Espa√±ol (dataset normal)
python train.py --direction agr2es --dataset_version v1 --epochs 12 --batch_size 16 --learning_rate 3e-5 --patience 3
```

### Con Dataset Extendido
```bash
# Espa√±ol ‚Üí Awaj√∫n (m√°s datos)
python train.py --direction es2agr --dataset_version v2 --epochs 15 --batch_size 16 --learning_rate 3e-5 --patience 4

# Awaj√∫n ‚Üí Espa√±ol (m√°s datos)  
python train.py --direction agr2es --dataset_version v2 --epochs 15 --batch_size 16 --learning_rate 3e-5 --patience 4
```

## ‚öôÔ∏è Experimentos con Diferentes Hiperpar√°metros

### Learning Rate Conservador
```bash
python train.py --direction es2agr --dataset_version v1 --epochs 15 --batch_size 16 --learning_rate 1e-5 --patience 5
```

### Batch Size Grande (si tienes GPU potente)
```bash
python train.py --direction es2agr --dataset_version v1 --epochs 10 --batch_size 32 --learning_rate 3e-5 --patience 3
```

### Entrenamiento Largo
```bash
python train.py --direction agr2es --dataset_version v2 --epochs 25 --batch_size 16 --learning_rate 3e-5 --patience 7
```

### GPU con Poca Memoria
```bash
python train.py --direction es2agr --dataset_version v1 --epochs 12 --batch_size 4 --learning_rate 2e-5 --patience 4
```

## üìä Monitoreo con MLflow

### Iniciar dashboard MLflow
```bash
mlflow ui
```
Luego abre: http://localhost:5000

### Ver experimentos espec√≠ficos
```bash
# Filtrar por dataset version
mlflow ui --backend-store-uri file:./mlruns

# En la interfaz web, filtrar por:
# - Experiment name contiene "v1" o "v2"  
# - Direction: "es2agr" o "agr2es"
```

## üõ†Ô∏è Comandos de Utilidad

### Verificar estructura de datos
```bash
ls -la data/awajun-spanish-v1/
ls -la data/awajun-spanish-v2/
```

### Ejecutar todos los experimentos autom√°ticamente
```bash
chmod +x run_experiments.sh
./run_experiments.sh
```

### Reanudar entrenamiento desde checkpoint
```bash
python train.py --direction es2agr --dataset_version v1 --resume runs/nllb_es2agr_20250715_143022
```

## üéØ Configuraci√≥n Recomendada por Caso

### Para tesis/demostraci√≥n
```bash
python train.py --direction es2agr --dataset_version v1 --epochs 10 --batch_size 16 --learning_rate 3e-5 --patience 3
```

### Para publicaci√≥n/paper
```bash
python train.py --direction es2agr --dataset_version v2 --epochs 20 --batch_size 16 --learning_rate 3e-5 --patience 5
```

### Para experimento r√°pido
```bash
python train.py --direction es2agr --dataset_version v1 --test_mode
```

## üìà Interpretaci√≥n de Resultados

### M√©tricas a observar en MLflow:
- **eval_chrf**: M√©trica principal (mayor = mejor)
- **eval_bleu**: M√©trica secundaria (mayor = mejor)  
- **best_epoch**: √âpoca del mejor modelo
- **early_stopped**: Si se activ√≥ early stopping
- **total_training_time_minutes**: Tiempo total

### Buenos resultados esperados:
- **CHRF++ > 45**: Traducci√≥n decente
- **CHRF++ > 55**: Traducci√≥n buena
- **CHRF++ > 65**: Traducci√≥n excelente