#!/bin/bash

# Script para ejecutar experimentos NLLB Awaj√∫n-Espa√±ol
# Solo 2 experimentos: es2agr y agr2es
# Dataset version como par√°metro dentro de cada run

echo "üöÄ Ejecutando experimentos NLLB Awaj√∫n-Espa√±ol"
echo "==============================================="

# ===== PRUEBA R√ÅPIDA =====
echo ""
echo "üß™ PRUEBA R√ÅPIDA - Verificaci√≥n de funcionamiento"
echo "---------------------------------------------------"

echo "1Ô∏è‚É£  Probando configuraci√≥n b√°sica..."
python3 train.py --direction es2agr --dataset_version v1 --test_mode --batch_size 16

echo ""
echo "‚úÖ Prueba b√°sica completada"
echo ""

# ===== EXPERIMENTOS ESPA√ëOL ‚Üí AWAJ√öN =====
echo "üî¨ EXPERIMENTO: ESPA√ëOL ‚Üí AWAJ√öN"
echo "================================"

# NLLB-600M experiments
echo "1Ô∏è‚É£  NLLB-600M | Dataset V1 | Sin balance"
python3 train.py --direction es2agr --dataset_version v1 --model_name facebook/nllb-200-distilled-600M --epochs 12 --batch_size 24 --learning_rate 3e-5 --patience 2 --config <(sed 's/balance_method: "weighted"/balance_method: "none"/' config.yaml)

echo "2Ô∏è‚É£  NLLB-600M | Dataset V1 | Con balance"
python3 train.py --direction es2agr --dataset_version v1 --model_name facebook/nllb-200-distilled-600M --epochs 12 --batch_size 24 --learning_rate 3e-5 --patience 2

echo "3Ô∏è‚É£  NLLB-600M | Dataset V2 | Sin balance"
python3 train.py --direction es2agr --dataset_version v2 --model_name facebook/nllb-200-distilled-600M --epochs 15 --batch_size 24 --learning_rate 3e-5 --patience 2 --config <(sed 's/balance_method: "weighted"/balance_method: "none"/' config.yaml)

echo "4Ô∏è‚É£  NLLB-600M | Dataset V2 | Con balance"
python3 train.py --direction es2agr --dataset_version v2 --model_name facebook/nllb-200-distilled-600M --epochs 15 --batch_size 24 --learning_rate 3e-5 --patience 2

# NLLB-1.3B experiments
echo "5Ô∏è‚É£  NLLB-1.3B | Dataset V1 | Sin balance"
python3 train.py --direction es2agr --dataset_version v1 --model_name facebook/nllb-200-distilled-1.3B --epochs 10 --batch_size 16 --learning_rate 2e-5 --patience 2 --config <(sed 's/balance_method: "weighted"/balance_method: "none"/' config.yaml)

echo "6Ô∏è‚É£  NLLB-1.3B | Dataset V1 | Con balance"
python3 train.py --direction es2agr --dataset_version v1 --model_name facebook/nllb-200-distilled-1.3B --epochs 10 --batch_size 16 --learning_rate 2e-5 --patience 2

echo "7Ô∏è‚É£  NLLB-1.3B | Dataset V2 | Sin balance"
python3 train.py --direction es2agr --dataset_version v2 --model_name facebook/nllb-200-distilled-1.3B --epochs 12 --batch_size 16 --learning_rate 2e-5 --patience 2 --config <(sed 's/balance_method: "weighted"/balance_method: "none"/' config.yaml)

echo "8Ô∏è‚É£  NLLB-1.3B | Dataset V2 | Con balance"
python3 train.py --direction es2agr --dataset_version v2 --model_name facebook/nllb-200-distilled-1.3B --epochs 12 --batch_size 16 --learning_rate 2e-5 --patience 2

# ===== EXPERIMENTOS AWAJ√öN ‚Üí ESPA√ëOL =====
echo ""
echo "üî¨ EXPERIMENTO: AWAJ√öN ‚Üí ESPA√ëOL"
echo "================================"

# NLLB-600M experiments
echo "9Ô∏è‚É£  NLLB-600M | Dataset V1 | Sin balance"
python3 train.py --direction agr2es --dataset_version v1 --model_name facebook/nllb-200-distilled-600M --epochs 12 --batch_size 24 --learning_rate 3e-5 --patience 2 --config <(sed 's/balance_method: "weighted"/balance_method: "none"/' config.yaml)

echo "üîü NLLB-600M | Dataset V1 | Con balance"
python3 train.py --direction agr2es --dataset_version v1 --model_name facebook/nllb-200-distilled-600M --epochs 12 --batch_size 24 --learning_rate 3e-5 --patience 2

echo "1Ô∏è‚É£1Ô∏è‚É£ NLLB-600M | Dataset V2 | Sin balance"
python3 train.py --direction agr2es --dataset_version v2 --model_name facebook/nllb-200-distilled-600M --epochs 15 --batch_size 24 --learning_rate 3e-5 --patience 2 --config <(sed 's/balance_method: "weighted"/balance_method: "none"/' config.yaml)

echo "1Ô∏è‚É£2Ô∏è‚É£ NLLB-600M | Dataset V2 | Con balance"
python3 train.py --direction agr2es --dataset_version v2 --model_name facebook/nllb-200-distilled-600M --epochs 15 --batch_size 24 --learning_rate 3e-5 --patience 2

# NLLB-1.3B experiments
echo "1Ô∏è‚É£3Ô∏è‚É£ NLLB-1.3B | Dataset V1 | Sin balance"
python3 train.py --direction agr2es --dataset_version v1 --model_name facebook/nllb-200-distilled-1.3B --epochs 10 --batch_size 16 --learning_rate 2e-5 --patience 2 --config <(sed 's/balance_method: "weighted"/balance_method: "none"/' config.yaml)

echo "1Ô∏è‚É£4Ô∏è‚É£ NLLB-1.3B | Dataset V1 | Con balance"
python3 train.py --direction agr2es --dataset_version v1 --model_name facebook/nllb-200-distilled-1.3B --epochs 10 --batch_size 16 --learning_rate 2e-5 --patience 2

echo "1Ô∏è‚É£5Ô∏è‚É£ NLLB-1.3B | Dataset V2 | Sin balance"
python3 train.py --direction agr2es --dataset_version v2 --model_name facebook/nllb-200-distilled-1.3B --epochs 12 --batch_size 16 --learning_rate 2e-5 --patience 2 --config <(sed 's/balance_method: "weighted"/balance_method: "none"/' config.yaml)

echo "1Ô∏è‚É£6Ô∏è‚É£ NLLB-1.3B | Dataset V2 | Con balance"
python3 train.py --direction agr2es --dataset_version v2 --model_name facebook/nllb-200-distilled-1.3B --epochs 12 --batch_size 16 --learning_rate 2e-5 --patience 2

echo ""
echo "üéâ Todos los experimentos completados!"
echo "üìä Revisa los resultados en MLflow:"
echo "   - Experimento: awajun_translation_es2agr"
echo "   - Experimento: awajun_translation_agr2es"
echo "üîó mlflow ui ‚Üí http://localhost:5000"